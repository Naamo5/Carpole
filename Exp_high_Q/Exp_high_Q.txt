#Set hyper parameters for the DQN. Do not adjust those labeled as Fixed.
self.discount_factor = 0.99
self.learning_rate = 0.001
self.epsilon = 0.02 #Fixed
self.batch_size = 32 #Fixed
self.memory_size = 2000
self.train_start = 1000 #Fixed
self.target_update_frequency = 5


################################################################################
################################################################################

#Number of test states for Q value plots
self.test_state_no = 10000

#Create memory buffer using deque
self.memory = deque(maxlen=self.memory_size)

#Create main network and target network (using build_model defined below)
self.model = self.build_model()
self.target_model = self.build_model()

#Initialize target network
self.update_target_model()

#Approximate Q function using Neural Network
#State is the input and the Q Values are the output.
###############################################################################
###############################################################################
#Edit the Neural Network model here
#Tip: Consult https://keras.io/getting-started/sequential-model-guide/
def build_model(self):
model = Sequential()
model.add(Dense(128, input_dim=self.state_size, activation='relu',
                kernel_initializer='he_uniform'))
model.add(Dense(128, input_dim=self.state_size, activation='relu',
                kernel_initializer='he_uniform'))
model.add(Dense(self.action_size, activation='linear',
                kernel_initializer='he_uniform'))
model.summary()
model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))
return model-
